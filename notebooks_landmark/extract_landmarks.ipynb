{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extraction\n",
    "\n",
    "For all videos in a dataset and for all landmarks, extract the RGB and BVP signals and evaluate the result.\n",
    "Save the result in a dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erolland\\AppData\\Roaming\\Python\\Python39\\site-packages\\cupy\\_environment.py:487: UserWarning: \n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  CuPy may not function correctly because multiple CuPy packages are installed\n",
      "  in your environment:\n",
      "\n",
      "    cupy, cupy-cuda11x\n",
      "\n",
      "  Follow these steps to resolve this issue:\n",
      "\n",
      "    1. For all packages listed above, run the following command to remove all\n",
      "       existing CuPy installations:\n",
      "\n",
      "         $ pip uninstall <package_name>\n",
      "\n",
      "      If you previously installed CuPy via conda, also run the following:\n",
      "\n",
      "         $ conda uninstall cupy\n",
      "\n",
      "    2. Install the appropriate CuPy package.\n",
      "       Refer to the Installation Guide for detailed instructions.\n",
      "\n",
      "         https://docs.cupy.dev/en/stable/install.html\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "  warnings.warn(f'''\n",
      "c:\\Users\\erolland\\.conda\\envs\\project\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\erolland\\.conda\\envs\\project\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing the dtw module. When using in academic works please cite:\n",
      "  T. Giorgino. Computing and Visualizing Dynamic Time Warping Alignments in R: The dtw Package.\n",
      "  J. Stat. Soft., doi:10.18637/jss.v031.i07.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyVHR as vhr\n",
    "import numpy as np\n",
    "from pyVHR.analysis.pipelineLandmarks import *\n",
    "import plotly.express as px\n",
    "\n",
    "import constants\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "vhr.plot.VisualizeParams.renderer = 'vscode' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract RGB\n",
    "\n",
    "- Extract windowed RGB traces for all landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all_landmarks: ['lower_medial_forehead', 'left_lower_lateral_forehead', 'right_lower_lateral_forehead', 'glabella', 'upper_nasal_dorsum', 'lower_nasal_dorsum', 'soft_triangle', 'left_ala', 'right_ala', 'nasal_tip', 'left_lower_nasal_sidewall', 'right_lower_nasal_sidewall', 'left_mid_nasal_sidewall', 'right_mid_nasal_sidewall', 'philtrum', 'left_upper_lip', 'right_upper_lip', 'left_nasolabial_fold', 'right_nasolabial_fold', 'left_temporal', 'right_temporal', 'left_malar', 'right_malar', 'left_lower_cheek', 'right_lower_cheek', 'chin', 'left_marionette_fold', 'right_marionette_fold']\n"
     ]
    }
   ],
   "source": [
    "## Args\n",
    "dataset_name = 'mr_nirp' \n",
    "methods = ['cupy_CHROM', 'cpu_LGI']\n",
    "roi_approach = 'landmark'\n",
    "sampling_method = 'random'\n",
    "nb_sample_points = 2000\n",
    "seconds = 60\n",
    "winsize = 10      \n",
    "stride = 10\n",
    "cuda = True\n",
    "\n",
    "pipeline = PipielineLandmarks()\n",
    "dataset = pipeline.get_dataset(dataset_name)\n",
    "allvideo = dataset.videoFilenames\n",
    "all_landmarks = list(vhr.extraction.utils.CustomLandmarks().get_all_landmarks().keys())\n",
    "print(f\"all_landmarks: {all_landmarks}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_data(landmark, videoFileName, windowed_sig, timesES):\n",
    "  \"\"\"\n",
    "  Add data to the dictionary\n",
    "  \"\"\"\n",
    "  \n",
    "  data = {}\n",
    "  data['dataset'] = dataset_name\n",
    "  data['videoIdx'] = allvideo.index(videoFileName)\n",
    "  data['videoFilename'] = constants.get_subject_name(dataset_name, videoFileName)\n",
    "  data['landmarks'] = landmark # single landmark\n",
    "  data['rPPG'] = windowed_sig\n",
    "  data['timesES'] = timesES\n",
    "\n",
    "  return data\n",
    "\n",
    "def reject_video(dataset_name, videoFileName):\n",
    "  \"\"\"\n",
    "  Reject videos that are not considered in the dataset\n",
    "  Args:\n",
    "    dataset_name: str\n",
    "    videoFileName: str\n",
    "  \"\"\"\n",
    "  if dataset_name == 'ubfc_phys' and 'T1' not in videoFileName:\n",
    "    return True\n",
    "  if dataset_name == 'mr_nirp' and 'still' not in videoFileName:\n",
    "    return True\n",
    "  for subject in constants.eliminated_subjects:\n",
    "    if subject in videoFileName:\n",
    "      return True\n",
    "  return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 D:/datasets_rppg/MR-NIRP_indoor\\Subject1_still_940-015\\Subject1_still_940\\RGB_corrected\\Subject1_still_940.avi\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [03:04<00:00, 92.29s/it]\n"
     ]
    }
   ],
   "source": [
    "datas = []\n",
    "\n",
    "for videoIdx in tqdm(range(len(allvideo[:2]))):\n",
    "    fname = dataset.getSigFilename(videoIdx)\n",
    "    videoFileName = dataset.getVideoFilename(videoIdx)\n",
    "    if reject_video(dataset_name, videoFileName):\n",
    "        continue\n",
    "    print(videoIdx, videoFileName)\n",
    "\n",
    "    for landmark in all_landmarks[:2]:\n",
    "        try:\n",
    "            windowed_sig, timesES = pipeline.extract_rgb([landmark], videoFileName, roi_approach, sampling_method, nb_sample_points, \n",
    "                                                         seconds, winsize, stride, verb=False, cuda=cuda)\n",
    "            data = add_data(landmark, videoFileName, windowed_sig, timesES)\n",
    "            datas.append(data)\n",
    "        except Exception as e:\n",
    "            print(\"Error in landmark \", landmark, \" for video \", videoFileName)\n",
    "            print(e)\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>videoIdx</th>\n",
       "      <th>videoFilename</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>rPPG</th>\n",
       "      <th>timesES</th>\n",
       "      <th>sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>lower_medial_forehead</td>\n",
       "      <td>[[[[99.857  99.021  99.1715 98.8615 98.9175 99...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>left_lower_lateral_forehead</td>\n",
       "      <td>[[[[83.0895 84.4545 82.879  83.1045 83.65   83...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  videoIdx       videoFilename                    landmarks  \\\n",
       "0  mr_nirp         1  Subject1_still_940        lower_medial_forehead   \n",
       "1  mr_nirp         1  Subject1_still_940  left_lower_lateral_forehead   \n",
       "\n",
       "                                                rPPG  \\\n",
       "0  [[[[99.857  99.021  99.1715 98.8615 98.9175 99...   \n",
       "1  [[[[83.0895 84.4545 82.879  83.1045 83.65   83...   \n",
       "\n",
       "                               timesES      sampling  \n",
       "0  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  \n",
       "1  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(datas)\n",
    "df['sampling'] = sampling_method + '_' + str(winsize) + '_' + str(stride)\n",
    "df['timesES'] = [timesES for i in df.index]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\erolland\\AppData\\Local\\Temp\\3\\ipykernel_22328\\301974329.py:3: PerformanceWarning: \n",
      "your performance may suffer as PyTables will pickle object types that it cannot\n",
      "map directly to c-types [inferred_type->mixed,key->block1_values] [items->Index(['dataset', 'videoFilename', 'landmark', 'bpmGT', 'rPPG', 'timesGT',\n",
      "       'timesES', 'sampling'],\n",
      "      dtype='object')]\n",
      "\n",
      "  df.to_hdf(f'../results/brightness_roi/lgi/{dataset_name.upper()}/{dataset_name.upper()}_rPPG_talk_60s.h5', key='df', mode='w')\n"
     ]
    }
   ],
   "source": [
    "# df.to_hdf(f'../result/{dataset_name.upper()}/{dataset_name.upper()}_rPPG.h5', key='df', mode='w')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract BVP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stride: 10, Winsize: 10, Duration: 60, Length: 6\n"
     ]
    }
   ],
   "source": [
    "## Args\n",
    "dataset_name = 'mr_nirp' \n",
    "methods = ['cupy_CHROM', 'cpu_LGI']\n",
    "roi_approach = 'landmark'\n",
    "sampling_method = 'random'\n",
    "nb_sample_points = 2000\n",
    "seconds = 60\n",
    "winsize = 10      \n",
    "stride = 10\n",
    "cuda = True\n",
    "\n",
    "pipeline = PipielineLandmarks()\n",
    "dataset = pipeline.get_dataset(dataset_name)\n",
    "allvideo = dataset.videoFilenames\n",
    "custom_landmarks = vhr.extraction.utils.CustomLandmarks()\n",
    "all_landmarks_names = list(custom_landmarks.get_all_landmarks().keys())\n",
    "videoFPS, sigFPS = constants.get_fps(dataset_name)\n",
    "\n",
    "overlap = winsize - stride\n",
    "length = int((seconds - winsize) / (winsize - overlap)) + 1 # Number of extracted windows\n",
    "print(f\"Stride: {stride}, Winsize: {winsize}, Duration: {seconds}, Length: {length}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12 ['glabella', 'upper_nasal_dorsum', 'lower_medial_forehead', 'soft_triangle', 'malar', 'lower_lateral_forehead', 'nasal_tip', 'chin', 'lower_cheek', 'ala', 'nasolabial_fold', 'marionette_fold']\n",
      "18 ['glabella', 'upper_nasal_dorsum', 'lower_medial_forehead', 'soft_triangle', 'right_malar', 'right_lower_lateral_forehead', 'nasal_tip', 'chin', 'right_lower_cheek', 'right_ala', 'right_nasolabial_fold', 'right_marionette_fold', 'left_malar', 'left_lower_lateral_forehead', 'left_lower_cheek', 'left_ala', 'left_nasolabial_fold', 'left_marionette_fold']\n"
     ]
    }
   ],
   "source": [
    "# Top landmarks: Landmarks considered in combinations\n",
    "top_ldmks = ['glabella', 'upper_nasal_dorsum', 'lower_medial_forehead', 'soft_triangle', 'malar', 'lower_lateral_forehead', 'nasal_tip', 'chin', 'lower_cheek', 'ala', 'nasolabial_fold', 'marionette_fold']\n",
    "print(len(top_ldmks), top_ldmks)\n",
    "\n",
    "# top_ldmks_sym : landmarks with left and right component as separate\n",
    "ldmk_names_dict = {ldmk.replace('left_', '').replace('right_', ''): ldmk for ldmk in all_landmarks_names} # name without left right: name with right\n",
    "top_ldmks_sym = [ldmk_names_dict[ldmk] for ldmk in top_ldmks]\n",
    "for ldmk in top_ldmks_sym:\n",
    "    if 'right_' in ldmk:\n",
    "        top_ldmks_sym.append(ldmk.replace('right', 'left'))\n",
    "print(len(top_ldmks_sym), top_ldmks_sym)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chosen_landmarks: 1573\n"
     ]
    }
   ],
   "source": [
    "# Landmarks choice\n",
    "case = 'combine'\n",
    "cases = ['ind_28', 'ind_18', 'combine']\n",
    "if case == 'combine':\n",
    "    all_landmarks = custom_landmarks.get_landmarks(case, min_len=2, max_len=5, all_landmarks_names=top_ldmks_sym)\n",
    "else:\n",
    "    all_landmarks = custom_landmarks.get_landmarks(case)\n",
    "print(f\"Chosen_landmarks: {len(all_landmarks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Single landmark: 28\n",
      "Dataset ['mr_nirp'] with 8 files\n",
      "Sampling:  ['random_10_10']\n",
      "Extracted video lenghth:  0.2 seconds\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>videoIdx</th>\n",
       "      <th>videoFilename</th>\n",
       "      <th>landmark</th>\n",
       "      <th>rPPG</th>\n",
       "      <th>timesES</th>\n",
       "      <th>sampling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>lower_medial_forehead</td>\n",
       "      <td>[[[[99.8145 99.135  99.0145 99.036  98.789  99...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>left_lower_lateral_forehead</td>\n",
       "      <td>[[[[82.3205 83.601  82.9905 83.351  83.4875 83...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>right_lower_lateral_forehead</td>\n",
       "      <td>[[[[67.4085 65.7125 65.085  66.156  65.9555 66...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>glabella</td>\n",
       "      <td>[[[[102.7315 101.3095 100.939  101.723  101.22...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>upper_nasal_dorsum</td>\n",
       "      <td>[[[[72.413  71.8355 71.229  72.01   71.951  71...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  videoIdx       videoFilename                      landmark  \\\n",
       "0  mr_nirp         1  Subject1_still_940         lower_medial_forehead   \n",
       "1  mr_nirp         1  Subject1_still_940   left_lower_lateral_forehead   \n",
       "2  mr_nirp         1  Subject1_still_940  right_lower_lateral_forehead   \n",
       "3  mr_nirp         1  Subject1_still_940                      glabella   \n",
       "4  mr_nirp         1  Subject1_still_940            upper_nasal_dorsum   \n",
       "\n",
       "                                                rPPG  \\\n",
       "0  [[[[99.8145 99.135  99.0145 99.036  98.789  99...   \n",
       "1  [[[[82.3205 83.601  82.9905 83.351  83.4875 83...   \n",
       "2  [[[[67.4085 65.7125 65.085  66.156  65.9555 66...   \n",
       "3  [[[[102.7315 101.3095 100.939  101.723  101.22...   \n",
       "4  [[[[72.413  71.8355 71.229  72.01   71.951  71...   \n",
       "\n",
       "                               timesES      sampling  \n",
       "0  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  \n",
       "1  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  \n",
       "2  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  \n",
       "3  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  \n",
       "4  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read extracted RGB signals\n",
    "df = pd.read_hdf(f'../result/{dataset_name.upper()}/{dataset_name.upper()}_rPPG.h5', key='df')\n",
    "\n",
    "print(f\"Single landmark: {df['landmark'].unique().size}\")\n",
    "print(f\"Dataset {df['dataset'].unique()} with {df['videoFilename'].unique().size} files\" )\n",
    "print(\"Sampling: \",  df['sampling'].unique()) \n",
    "print(\"Extracted video lenghth: \", len(df.loc[0, 'rPPG']) / videoFPS, \"seconds\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.82s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract BVP and evaluate results\n",
    "\n",
    "res = pyVHR.analysis.pipelineLandmarks.TestResult()\n",
    "\n",
    "for videoIdx in tqdm(df.videoIdx.unique()[:1]):\n",
    "    try:\n",
    "        ### Get PPG signal data\n",
    "        PPG_win, bpmGT, timesGT, videoFileName = pipeline.get_signal_data(videoIdx, dataset)\n",
    "    except Exception as e:\n",
    "        print(f\"Error in {videoIdx} {videoFileName}: {e}\")\n",
    "        continue\n",
    "\n",
    "    for landmarks in all_landmarks[:1]:\n",
    "        try:    \n",
    "            timesES = df['timesES'].iloc[0]\n",
    "\n",
    "            rppgs = df.loc[(df['videoFilename'] == videoFileName) & (df['landmark'].isin(landmarks)), 'rPPG',].to_numpy()\n",
    "            windowed_sig = np.concatenate([rppg for rppg in rppgs], axis=1)            \n",
    "            windowed_sig = windowed_sig[:int(seconds/winsize)] # only take seconds length, here 60s\n",
    "            timesES = timesES[:int(seconds/winsize)] # only take seconds length, here 60s\n",
    "\n",
    "            for method in methods:\n",
    "                bvps_win, timesES, bpmES = pipeline.extract_bpm(windowed_sig, timesES, videoFPS, roi_approach, method,winsize=winsize, cuda=cuda)\n",
    "                res = pipeline.evaluate_extraction(bvps_win, bpmES, bpmGT, timesES, timesGT, PPG_win, videoFPS, res, method, videoFileName, landmarks)\n",
    "        except Exception as e:\n",
    "            print(f\"Error in {videoIdx} {videoFileName}: {e}\")\n",
    "            continue\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Landmark: 1\n",
      "Dataset ['mr_nirp'] with 1 files\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>dataset</th>\n",
       "      <th>videoFilename</th>\n",
       "      <th>videoIdx</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PCC</th>\n",
       "      <th>CCC</th>\n",
       "      <th>SNR</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MAD</th>\n",
       "      <th>rPPG_PCC</th>\n",
       "      <th>DTW</th>\n",
       "      <th>bpmGT</th>\n",
       "      <th>bpmES</th>\n",
       "      <th>timeGT</th>\n",
       "      <th>timeES</th>\n",
       "      <th>sampling</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cupy_CHROM</td>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>1</td>\n",
       "      <td>(right_lower_lateral_forehead, left_malar, rig...</td>\n",
       "      <td>0.464733</td>\n",
       "      <td>0.354167</td>\n",
       "      <td>0.934642</td>\n",
       "      <td>0.934397</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.002930</td>\n",
       "      <td></td>\n",
       "      <td>-0.112263</td>\n",
       "      <td>1.960439</td>\n",
       "      <td>[76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....</td>\n",
       "      <td>[75.8056640625, 77.1240234375, 79.3212890625, ...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "      <td>cheeks_forehead</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cpu_LGI</td>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>1</td>\n",
       "      <td>(right_lower_lateral_forehead, left_malar, rig...</td>\n",
       "      <td>0.585209</td>\n",
       "      <td>0.477702</td>\n",
       "      <td>0.913093</td>\n",
       "      <td>0.906656</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.222656</td>\n",
       "      <td></td>\n",
       "      <td>0.131464</td>\n",
       "      <td>1.748074</td>\n",
       "      <td>[76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....</td>\n",
       "      <td>[75.5859375, 77.1240234375, 79.7607421875, 78....</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>random_10_10</td>\n",
       "      <td>cheeks_forehead</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       method  dataset       videoFilename  videoIdx  \\\n",
       "0  cupy_CHROM  mr_nirp  Subject1_still_940         1   \n",
       "1     cpu_LGI  mr_nirp  Subject1_still_940         1   \n",
       "\n",
       "                                           landmarks      RMSE       MAE  \\\n",
       "0  (right_lower_lateral_forehead, left_malar, rig...  0.464733  0.354167   \n",
       "1  (right_lower_lateral_forehead, left_malar, rig...  0.585209  0.477702   \n",
       "\n",
       "        PCC       CCC  SNR       MAX MAD  rPPG_PCC       DTW  \\\n",
       "0  0.934642  0.934397  NaN  1.002930     -0.112263  1.960439   \n",
       "1  0.913093  0.906656  NaN  1.222656      0.131464  1.748074   \n",
       "\n",
       "                                               bpmGT  \\\n",
       "0  [76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....   \n",
       "1  [76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....   \n",
       "\n",
       "                                               bpmES  \\\n",
       "0  [75.8056640625, 77.1240234375, 79.3212890625, ...   \n",
       "1  [75.5859375, 77.1240234375, 79.7607421875, 78....   \n",
       "\n",
       "                                              timeGT  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "1  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                                timeES      sampling           region  \n",
       "0  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  cheeks_forehead  \n",
       "1  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]  random_10_10  cheeks_forehead  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Format the dataframe for results\n",
    "df_res = res.dataFrame\n",
    "df_res['dataset'] = dataset_name\n",
    "df_res['sampling'] = sampling_method + '_' + str(winsize) + '_' + str(stride)\n",
    "\n",
    "# More readabale videoFilename and videoIdx\n",
    "df_res['videoFilename'] = df_res['videoFilename'].apply(lambda x: constants.get_subject_name(dataset_name, x))\n",
    "indexes = {i: constants.get_subject_name(dataset_name, video) for i, video in enumerate(allvideo)}\n",
    "indexes = pd.DataFrame({'videoIdx':list(indexes.keys()), 'videoFilename':list(indexes.values())})\n",
    "df_res = df_res.drop(columns=['videoIdx'])\n",
    "df_res.insert(3, 'videoIdx', df_res['videoFilename'].map(indexes.set_index('videoFilename')['videoIdx']))\n",
    "\n",
    "# Map the landmarks to the corresponding face regions\n",
    "face_regions = pyVHR.analysis.CustomLandmarks().get_face_regions()\n",
    "# for roi in list(face_regions.keys()):\n",
    "#     df_res.loc[df_res['landmarks'].apply(lambda x: x[0]).isin(face_regions[f'{roi}']),'ROI'] = roi\n",
    "if case == 'ind_18' or case == 'ind_28': \n",
    "  for face_region in list(face_regions.keys()):\n",
    "      df_res.loc[df_res['landmarks'].apply(lambda x: x[0]).isin(face_regions[f'{face_regions}']),'region'] = face_region\n",
    "if case == 'combine':\n",
    "  ldmk_roi = {landmark: face_region for face_region, landmarks in face_regions.items() for landmark in landmarks}\n",
    "  df_res['region'] = df_res['landmarks'].apply(lambda x: '_'.join(set([ldmk_roi[landmark] for landmark in x])))\n",
    "\n",
    "\n",
    "print(f\"Landmark: {df_res['landmarks'].unique().size}\")\n",
    "print(f\"Dataset {df_res['dataset'].unique()} with {df_res['videoFilename'].unique().size} files\" )\n",
    "df_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>videoIdx</th>\n",
       "      <th>videoFilename</th>\n",
       "      <th>method</th>\n",
       "      <th>landmarks</th>\n",
       "      <th>bpmGT</th>\n",
       "      <th>bpmES</th>\n",
       "      <th>timeGT</th>\n",
       "      <th>timeES</th>\n",
       "      <th>BVP_win</th>\n",
       "      <th>RMSE</th>\n",
       "      <th>MAE</th>\n",
       "      <th>PCC</th>\n",
       "      <th>timePCC</th>\n",
       "      <th>timeDTW</th>\n",
       "      <th>SNR</th>\n",
       "      <th>ROI</th>\n",
       "      <th>config</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mr_nirp</td>\n",
       "      <td>1</td>\n",
       "      <td>Subject1_still_940</td>\n",
       "      <td>cupy_CHROM</td>\n",
       "      <td>(lower_medial_forehead,)</td>\n",
       "      <td>[76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....</td>\n",
       "      <td>[75.5859375, 76.46484375, 79.1015625, 78.22265...</td>\n",
       "      <td>[0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...</td>\n",
       "      <td>[5.0, 15.0, 25.0, 35.0, 45.0, 55.0]</td>\n",
       "      <td>[[[-0.0008787291958837653, -0.162179957684393,...</td>\n",
       "      <td>0.801997</td>\n",
       "      <td>0.68099</td>\n",
       "      <td>0.863737</td>\n",
       "      <td>0.375969</td>\n",
       "      <td>2.208592</td>\n",
       "      <td>[0.46733564231544733]</td>\n",
       "      <td>forehead</td>\n",
       "      <td>2000_win10-0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dataset  videoIdx       videoFilename      method  \\\n",
       "0  mr_nirp         1  Subject1_still_940  cupy_CHROM   \n",
       "\n",
       "                  landmarks  \\\n",
       "0  (lower_medial_forehead,)   \n",
       "\n",
       "                                               bpmGT  \\\n",
       "0  [76.5, 76.5, 76.5, 76.5, 76.5, 76.0, 76.0, 76....   \n",
       "\n",
       "                                               bpmES  \\\n",
       "0  [75.5859375, 76.46484375, 79.1015625, 78.22265...   \n",
       "\n",
       "                                              timeGT  \\\n",
       "0  [0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, ...   \n",
       "\n",
       "                                timeES  \\\n",
       "0  [5.0, 15.0, 25.0, 35.0, 45.0, 55.0]   \n",
       "\n",
       "                                             BVP_win      RMSE      MAE  \\\n",
       "0  [[[-0.0008787291958837653, -0.162179957684393,...  0.801997  0.68099   \n",
       "\n",
       "        PCC   timePCC   timeDTW                    SNR       ROI        config  \n",
       "0  0.863737  0.375969  2.208592  [0.46733564231544733]  forehead  2000_win10-0  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = f'../result/{dataset_name.upper()}/'\n",
    "filenames = {'ind_28':'28', 'ind_18':'18', 'combine':'combine'}\n",
    "filename = path+f'{dataset_name.upper()}_{filenames[case]}.h5'\n",
    "\n",
    "print(filename)\n",
    "# df_res.to_hdf(filename, key='df', mode='w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

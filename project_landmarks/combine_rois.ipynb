{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Goal: Investigate different landmarks on LGI-PPGI\n",
    "\n",
    "a. Raw Signal Extraction\n",
    "- Skin extraction: convex hull\n",
    "- 468 keypoints: patch, landmarks definition from thesis\n",
    "    - Modified, should it also include the points inside and not just contour ? \n",
    "- 28 ROIs --> TODO how to combine them ? \n",
    "- Raw RGB Traces\n",
    "\n",
    "b. HR Estimation \n",
    "- rPPG Methods: OMIT, POS, CHROM, LGI\n",
    "- BVP Signal\n",
    "- Estimated HR Values\n",
    "- Evaluation: MAE, PCC + RMSE, SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pyVHR as vhr\n",
    "import numpy as np\n",
    "from pyVHR.analysis.pipeline import Pipeline\n",
    "from pyVHR.plot.visualize import *\n",
    "import os\n",
    "import plotly.express as px\n",
    "from pyVHR.utils.errors import getErrors, printErrors, displayErrors\n",
    "\n",
    "import constants\n",
    "import pandas as pd\n",
    "import pyVHR.analysis.pipelineLandmarks as custom_pipeline\n",
    "\n",
    "vhr.plot.VisualizeParams.renderer = 'vscode' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 D:/datasets_rppg/MR-NIRP_indoor\\Subject1_motion_940\\Subject1_motion_940\\RGB_corrected\\Subject1_motion_940.avi\n",
      "1 D:/datasets_rppg/MR-NIRP_indoor\\Subject1_still_940-015\\Subject1_still_940\\RGB_corrected\\Subject1_still_940.avi\n",
      "2 D:/datasets_rppg/MR-NIRP_indoor\\Subject2_motion_940\\Subject2_motion_940\\RGB_corrected\\Subject2_motion_940.avi\n",
      "3 D:/datasets_rppg/MR-NIRP_indoor\\Subject2_still_940-002\\Subject2_still_940\\RGB_corrected\\Subject2_still_940.avi\n",
      "4 D:/datasets_rppg/MR-NIRP_indoor\\Subject3_motion_940\\Subject3_motion_940\\RGB_corrected\\Subject3_motion_940.avi\n",
      "5 D:/datasets_rppg/MR-NIRP_indoor\\Subject3_still_940-012\\Subject3_still_940\\RGB_corrected\\Subject3_still_940.avi\n",
      "6 D:/datasets_rppg/MR-NIRP_indoor\\Subject4_motion_940\\Subject4_motion_940\\RGB_corrected\\Subject4_motion_940.avi\n",
      "7 D:/datasets_rppg/MR-NIRP_indoor\\Subject4_still_940-004\\Subject4_still_940\\RGB_corrected\\Subject4_still_940.avi\n",
      "8 D:/datasets_rppg/MR-NIRP_indoor\\Subject5_still_940-003\\Subject5_still_940\\RGB_corrected\\Subject5_still_940.avi\n",
      "9 D:/datasets_rppg/MR-NIRP_indoor\\Subject6_motion_940-008\\Subject6_motion_940\\RGB_corrected\\Subject6_motion_940.avi\n",
      "10 D:/datasets_rppg/MR-NIRP_indoor\\Subject6_still_940-005\\Subject6_still_940\\RGB_corrected\\Subject6_still_940.avi\n",
      "11 D:/datasets_rppg/MR-NIRP_indoor\\Subject7_motion_940\\Subject7_motion_940\\RGB_corrected\\Subject7_motion_940.avi\n",
      "12 D:/datasets_rppg/MR-NIRP_indoor\\Subject7_still_940-010\\Subject7_still_940\\RGB_corrected\\Subject7_still_940.avi\n",
      "13 D:/datasets_rppg/MR-NIRP_indoor\\Subject8_motion_940\\Subject8_motion_940\\RGB_corrected\\Subject8_motion_940.avi\n",
      "14 D:/datasets_rppg/MR-NIRP_indoor\\Subject8_still_940-001\\Subject8_still_940\\RGB_corrected\\Subject8_still_940.avi\n"
     ]
    }
   ],
   "source": [
    "# -- LOAD A DATASET\n",
    "\n",
    "dataset_name = 'mr_nirp'    \n",
    "video_DIR, BVP_DIR = constants.get_dataset_paths(dataset_name)\n",
    "\n",
    "dataset = vhr.datasets.datasetFactory(dataset_name, videodataDIR=video_DIR, BVPdataDIR=BVP_DIR)\n",
    "allvideo = dataset.videoFilenames\n",
    "\n",
    "# print the list of video names with the progressive index (idx)\n",
    "for v in range(len(allvideo)):\n",
    "  print(v, allvideo[v])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patch size for mr_nirp is 60 \n",
      "Testing ROI = mustache with minimum 2 landmarks\n"
     ]
    }
   ],
   "source": [
    "# -- PARAMETER SETTING\n",
    "\n",
    "roi = 'mustache'      # jaw, forehead, cheeks, nose, temple, lip\n",
    "wsize = 8        # seconds of video processed (with overlapping) for each estimate \n",
    "min_len = 2     # minimum number of landmarks tested\n",
    "patch_size = constants.get_patch_size(dataset_name)\n",
    "print(f\"Patch size for {dataset_name} is {patch_size} \")\n",
    "print(f\"Testing ROI = {roi} with minimum {min_len} landmarks\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = {\n",
    "  'forehead': [   \n",
    "      'lower_medial_forehead','glabella','left_lower_lateral_forehead','right_lower_lateral_forehead'\n",
    "    ],\n",
    " 'nose': [\n",
    "    'upper_nasal_dorsum','lower_nasal_dorsum','left_mid_nasal_sidewall','right_mid_nasal_sidewall','left_lower_nasal_sidewall',\n",
    "    'right_lower_nasal_sidewall','nasal_tip','soft_triangle','left_ala','right_ala'\n",
    "  ],\n",
    "  'cheeks':[\n",
    "    'left_malar','right_malar', 'left_lower_cheek','right_lower_cheek'\n",
    "  ],\n",
    "  'jaw':[\n",
    "    'left_marionette_fold','right_marionette_fold','chin'\n",
    "  ],\n",
    "  'temple':[\n",
    "    'left_temporal','right_temporal'\n",
    "  ],\n",
    "  'mustache':[\n",
    "    'left_nasolabial_fold','right_nasolabial_fold','left_upper_lip','right_upper_lip','philtrum'\n",
    "  ],\n",
    "}\n",
    "\n",
    "forehead_params = [['left_lower_lateral_forehead', 'right_lower_lateral_forehead'], ['glabella', 'lower_medial_forehead'],  ['left_lower_lateral_forehead', 'lower_medial_forehead', 'right_lower_lateral_forehead'],['glabella', 'left_lower_lateral_forehead', 'right_lower_lateral_forehead'],['glabella', 'left_lower_lateral_forehead', 'lower_medial_forehead', 'right_lower_lateral_forehead']]\n",
    "cheeks_params =  [['left_malar', 'right_malar'], ['left_lower_cheek', 'right_lower_cheek'], ['left_lower_cheek', 'left_malar', 'right_lower_cheek', 'right_malar']]\n",
    "jaw_params = [['left_marionette_fold', 'right_marionette_fold'], ['chin', 'left_marionette_fold', 'right_marionette_fold']]\n",
    "mustache_params = [['left_nasolabial_fold', 'right_nasolabial_fold'], ['left_upper_lip', 'right_upper_lip'], ['left_nasolabial_fold', 'philtrum', 'right_nasolabial_fold'], ['left_upper_lip', 'philtrum', 'right_upper_lip'], ['left_nasolabial_fold', 'left_upper_lip', 'right_nasolabial_fold', 'right_upper_lip'], ['left_nasolabial_fold', 'left_upper_lip', 'philtrum', 'right_nasolabial_fold', 'right_upper_lip']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{('forehead', 'cheeks'): ['lower_medial_forehead', 'glabella', 'left_lower_lateral_forehead', 'right_lower_lateral_forehead', 'left_malar', 'right_malar', 'left_lower_cheek', 'right_lower_cheek'], ('forehead', 'jaw'): ['lower_medial_forehead', 'glabella', 'left_lower_lateral_forehead', 'right_lower_lateral_forehead', 'left_marionette_fold', 'right_marionette_fold', 'chin'], ('jaw', 'cheeks'): ['left_marionette_fold', 'right_marionette_fold', 'chin', 'left_malar', 'right_malar', 'left_lower_cheek', 'right_lower_cheek']}\n"
     ]
    }
   ],
   "source": [
    "roi_combinations = [('forehead', 'cheeks'), ('forehead', 'jaw'), ('jaw', 'cheeks')]\n",
    "landmarks_dict = dict()\n",
    "for roi_combination in roi_combinations:\n",
    "    landmarks_dict[roi_combination] = [ldmk for roi in list(map(rois.get, roi_combination)) for ldmk in roi]\n",
    "landmarks_list = list(landmarks_dict.values())\n",
    "print(landmarks_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombineLandmarks:\n",
    "    def __init__(self, videos, dataset, winsize, patch_size, pipeline, methods=['cupy_CHROM'], verb=False):\n",
    "        self.dataset = dataset\n",
    "        self.winsize = winsize\n",
    "        self.patch_size = patch_size\n",
    "        self.methods = methods\n",
    "        self.pipeline = pipeline\n",
    "        self.res = pd.DataFrame()\n",
    "        self.verb = verb\n",
    "\n",
    "        # Load ground truth data\n",
    "        self.sigGT = []\n",
    "        self.timesGT = []\n",
    "        self.bpmGT = []\n",
    "        self.videoFileName = []\n",
    "        self.losses = []\n",
    "        self.load_ground_truth(videos)\n",
    "\n",
    "    def load_ground_truth(self, videos):\n",
    "        for videoIdx in videos:\n",
    "            try: \n",
    "                fname = dataset.getSigFilename(videoIdx)\n",
    "                sigGT = dataset.readSigfile(fname)\n",
    "                bpmGT, timesGT = sigGT.getBPM(self.winsize)\n",
    "                self.sigGT.append(sigGT)\n",
    "                self.bpmGT.append(bpmGT)\n",
    "                self.timesGT.append(timesGT)\n",
    "                self.videoFileName.append(dataset.getVideoFilename(videoIdx))\n",
    "                self.fps = vhr.extraction.get_fps(self.videoFileName[-1]) # assuming they are all the same\n",
    "            except Exception as e:\n",
    "                print(f\"{videoIdx}: {e}\")\n",
    "                continue\n",
    "        print('Video name: ', {len(self.videoFileName)}, self.videoFileName)\n",
    "        print('Video frame rate: ',self.fps)\n",
    "\n",
    "    def process(self,landmarks):\n",
    "        losses = []\n",
    "        for i, videoName in enumerate(self.videoFileName):\n",
    "            print(videoName)\n",
    "            res = self.pipeline.run_on_video_multimethods(\n",
    "                    ldmks_list=landmarks, \n",
    "                    videoFileName=self.videoFileName[i], bpmGT=self.bpmGT[i], timesGT=self.timesGT[i], \n",
    "                    methods=self.methods, winsize=self.winsize, patch_size=self.patch_size,\n",
    "                    verb=self.verb\n",
    "                )\n",
    "            losses.append(res.dict['RMSE'][0]) # suppose we are minimizing RMSE\n",
    "            self.res = pd.concat([self.res, res.dataFrame])\n",
    "        print(f\"Total loss for {ldmks_list}: {sum(losses)}\")\n",
    "        self.losses.append(losses)\n",
    "\n",
    "    def fit(self, landmarks_list):\n",
    "        for landmarks in landmarks_list:\n",
    "            print(\"Processing landmarks: \", landmarks)\n",
    "            self.process(landmarks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video name:  {1} ['D:/datasets_rppg/MR-NIRP_indoor\\\\Subject1_motion_940\\\\Subject1_motion_940\\\\RGB_corrected\\\\Subject1_motion_940.avi']\n",
      "Video frame rate:  30.0\n",
      "D:/datasets_rppg/MR-NIRP_indoor\\Subject1_motion_940\\Subject1_motion_940\\RGB_corrected\\Subject1_motion_940.avi\n",
      "Total loss for ['left_nasolabial_fold', 'right_nasolabial_fold', 'left_upper_lip', 'right_upper_lip', 'philtrum']: 1.7513122899945066\n"
     ]
    }
   ],
   "source": [
    "pl = custom_pipeline.LandmarksPipeline()\n",
    "# np.arange(0, len(dataset.videoFilenames))\n",
    "model = CombineLandmarks([0], dataset, wsize, patch_size, pl, methods=['cupy_CHROM'], verb=False)\n",
    "model.fit([landmarks_list[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['landmarks'] = df['landmarks'].apply(lambda x: tuple(x))\n",
    "# df['dataset'] = f'{dataset_name}_{roi}'\n",
    "# if dataset_name == 'lgi_ppgi':\n",
    "#   df['videoFilename'] = df.videoFilename.apply(lambda x: x.split('\\\\')[2])\n",
    "# if dataset_name == 'mr_nirp':\n",
    "#   df['videoFilename'] = df.videoFilename.apply(lambda x: x.split('\\\\')[2])\n",
    "indexes = {}\n",
    "for v in range(len(allvideo)):\n",
    "  indexes[allvideo[v].split('\\\\')[2]] = v\n",
    "indexes = pd.DataFrame({'videoIdx':list(indexes.values()), 'videoFilename':list(indexes.keys())})\n",
    "df = df.drop(columns=['sigFilename', 'bpmES_mad', 'videoIdx'])\n",
    "df.insert(3, 'videoIdx', df['videoFilename'].map(indexes.set_index('videoFilename')['videoIdx']))\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "df.insert(11, 'DTW', None)\n",
    "for row in df.itertuples():\n",
    "  distance, path = fastdtw(row.bpmGT, row.bpmES)\n",
    "  df.loc[row.Index, 'DTW'] = [distance]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>(forehead, cheeks)</th>\n",
       "      <td>lower_medial_forehead</td>\n",
       "      <td>glabella</td>\n",
       "      <td>left_lower_lateral_forehead</td>\n",
       "      <td>right_lower_lateral_forehead</td>\n",
       "      <td>left_malar</td>\n",
       "      <td>right_malar</td>\n",
       "      <td>left_lower_cheek</td>\n",
       "      <td>right_lower_cheek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(forehead, jaw)</th>\n",
       "      <td>lower_medial_forehead</td>\n",
       "      <td>glabella</td>\n",
       "      <td>left_lower_lateral_forehead</td>\n",
       "      <td>right_lower_lateral_forehead</td>\n",
       "      <td>left_marionette_fold</td>\n",
       "      <td>right_marionette_fold</td>\n",
       "      <td>chin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>(jaw, cheeks)</th>\n",
       "      <td>left_marionette_fold</td>\n",
       "      <td>right_marionette_fold</td>\n",
       "      <td>chin</td>\n",
       "      <td>left_malar</td>\n",
       "      <td>right_malar</td>\n",
       "      <td>left_lower_cheek</td>\n",
       "      <td>right_lower_cheek</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        0                      1  \\\n",
       "(forehead, cheeks)  lower_medial_forehead               glabella   \n",
       "(forehead, jaw)     lower_medial_forehead               glabella   \n",
       "(jaw, cheeks)        left_marionette_fold  right_marionette_fold   \n",
       "\n",
       "                                              2                             3  \\\n",
       "(forehead, cheeks)  left_lower_lateral_forehead  right_lower_lateral_forehead   \n",
       "(forehead, jaw)     left_lower_lateral_forehead  right_lower_lateral_forehead   \n",
       "(jaw, cheeks)                              chin                    left_malar   \n",
       "\n",
       "                                       4                      5  \\\n",
       "(forehead, cheeks)            left_malar            right_malar   \n",
       "(forehead, jaw)     left_marionette_fold  right_marionette_fold   \n",
       "(jaw, cheeks)                right_malar       left_lower_cheek   \n",
       "\n",
       "                                    6                  7  \n",
       "(forehead, cheeks)   left_lower_cheek  right_lower_cheek  \n",
       "(forehead, jaw)                  chin               None  \n",
       "(jaw, cheeks)       right_lower_cheek               None  "
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame.from_dict(landmarks_dict, orient='index',)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
